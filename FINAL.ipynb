{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ac934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 requests-2.32.3 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp310-cp310-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.2.5 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting meteostat\n",
      "  Using cached meteostat-1.6.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pandas>=1.1 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from meteostat) (2.2.3)\n",
      "Requirement already satisfied: pytz in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from meteostat) (2025.2)\n",
      "Requirement already satisfied: numpy in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from meteostat) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from pandas>=1.1->meteostat) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from pandas>=1.1->meteostat) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.17.0)\n",
      "Using cached meteostat-1.6.8-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: meteostat\n",
      "Successfully installed meteostat-1.6.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting geopy\n",
      "  Using cached geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Using cached geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [geopy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (2.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow-macos\n",
      "  Downloading tensorflow_macos-2.16.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.2.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (80.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from tensorflow-metal) (0.45.1)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading optree-0.15.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/patricknagy/miniforge3/envs/tf-m1/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow_macos-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.0/227.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl (389 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_metal-1.2.0-cp310-cp310-macosx_12_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-macosx_11_0_arm64.whl (329 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-metal, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, grpcio, google-pasta, gast, astunparse, absl-py, werkzeug, ml-dtypes, markdown-it-py, h5py, tensorboard, rich, keras, tensorflow, tensorflow-macos\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling numpy-2.2.5:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [tensorflow-macos][tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.9 numpy-1.26.4 opt-einsum-3.4.0 optree-0.15.0 protobuf-4.25.7 rich-14.0.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-macos-2.16.2 tensorflow-metal-1.2.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install meteostat\n",
    "%pip install geopy\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%pip install tensorflow-macos tensorflow-metal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435fa211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data for 2020\n",
      "getting data for 2021\n",
      "getting data for 2022\n",
      "getting data for 2023\n",
      "getting data for 2024\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Started           1338 non-null   object \n",
      " 1   AcresBurned       1288 non-null   float64\n",
      " 2   Longitude         1338 non-null   float64\n",
      " 3   Type              1338 non-null   object \n",
      " 4   Latitude          1338 non-null   float64\n",
      " 5   ExtinguishedDate  1338 non-null   object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 62.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for year in [2020, 2021, 2022, 2023, 2024]:\n",
    "    url = f'https://incidents.fire.ca.gov/umbraco/api/IncidentApi/List?inactive=true&year={year}'\n",
    "    print(f'getting data for {year}')\n",
    "    request = requests.get(url)\n",
    "    data = request.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[['Started', 'AcresBurned', 'Longitude','Type', 'Latitude', 'ExtinguishedDate']]\n",
    "    df = df[df['Type'] != 'Earthquake']\n",
    "    dfs.append(df)\n",
    "\n",
    "total_frame = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(total_frame.info())\n",
    "total_frame.to_csv('filtered_incidents.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4a26dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tavg  tmin  tmax  prcp  snow   wdir  wspd  wpgt  pres  tsun\n",
      "time                                                                   \n",
      "2020-02-24   4.9  -3.0  14.0   NaN   NaN  342.0   6.7   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "from meteostat import Point, Daily\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "row = total_frame.loc[3]\n",
    "\n",
    "# Parse 'Started' string to datetime\n",
    "start_date = datetime.strptime(row['Started'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "end_date = start_date + timedelta(days=1)\n",
    "\n",
    "# Create location point\n",
    "loc = Point(row['Latitude'], row['Longitude'])\n",
    "\n",
    "# Fetch daily weather data\n",
    "data = Daily(loc, start_date, end_date)\n",
    "data = data.fetch()\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7bcf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 163 entries, 69002 to ZGK9P\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   name           163 non-null    object        \n",
      " 1   country        163 non-null    string        \n",
      " 2   region         163 non-null    string        \n",
      " 3   wmo            53 non-null     string        \n",
      " 4   icao           159 non-null    string        \n",
      " 5   latitude       163 non-null    float64       \n",
      " 6   longitude      163 non-null    float64       \n",
      " 7   elevation      163 non-null    float64       \n",
      " 8   timezone       163 non-null    string        \n",
      " 9   hourly_start   159 non-null    datetime64[ns]\n",
      " 10  hourly_end     159 non-null    datetime64[ns]\n",
      " 11  daily_start    154 non-null    datetime64[ns]\n",
      " 12  daily_end      154 non-null    datetime64[ns]\n",
      " 13  monthly_start  138 non-null    datetime64[ns]\n",
      " 14  monthly_end    138 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](6), float64(3), object(1), string(5)\n",
      "memory usage: 20.4+ KB\n"
     ]
    }
   ],
   "source": [
    "from meteostat import Stations\n",
    "\n",
    "stations = Stations()\n",
    "cali_stations_list = stations.region('US', 'CA')\n",
    "print(cali_stations_list.count())\n",
    "cali_stations = cali_stations_list.fetch()\n",
    "\n",
    "cali_stations.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b260e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Latitude normalization has been prohibited in the newer versions of geopy, because the normalized value happened to be on a different pole, which is probably not what was meant. If you pass coordinates as positional args, please make sure that the order is (latitude, longitude) or (y, x) in Cartesian terms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at fire index 167 Latitude must be in the [-90; 90] range.\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the storage dictionary\n",
    "station_fires = defaultdict(list)\n",
    "\n",
    "# Convert station list to records (so you can easily iterate)\n",
    "stations = cali_stations.to_dict('records')\n",
    "\n",
    "# Loop through each fire\n",
    "for index, fire_row in total_frame.iterrows():\n",
    "    try:\n",
    "        fire_point = (fire_row['Latitude'], fire_row['Longitude'])\n",
    "\n",
    "        # Find closest station\n",
    "        closest_station = min(\n",
    "            stations,\n",
    "            key=lambda s: geodesic(fire_point, (s['latitude'], s['longitude'])).km\n",
    "        )\n",
    "\n",
    "\n",
    "        station_id = closest_station['name']  # adjust key name if needed\n",
    "\n",
    "        # Convert fire row to dict and add to the list for this station\n",
    "        station_fires[station_id].append(fire_row.to_dict())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error at fire index {index}\", e)\n",
    "        continue\n",
    "\n",
    "# Example: print counts per station\n",
    "total_fires = 0 \n",
    "for station_id, fires in station_fires.items():\n",
    "    total_fires += len(fires)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a429835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "station_daily_status = {}\n",
    "\n",
    "start_day = datetime(2020, 1, 1)\n",
    "end_day = datetime.today()\n",
    "date_range = [start_day + timedelta(days=i) for i in range((end_day - start_day).days - 1)]\n",
    "\n",
    "for station_id, fires in station_fires.items():\n",
    "\n",
    "    start_dates = [datetime.strptime(f['Started'], \"%Y-%m-%dT%H:%M:%SZ\") for f in fires]\n",
    "    start_dates.sort()\n",
    "\n",
    "    daily_status = {}\n",
    "    for current_date in date_range:\n",
    "        window_start = current_date - timedelta(days=5)\n",
    "        in_window = any(window_start <= d <= current_date for d in start_dates)\n",
    "        daily_status[current_date.strftime(\"%Y-%m-%d\")] = in_window\n",
    "\n",
    "    station_daily_status[station_id] = daily_status\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85b57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing weather for station Fortuna / Alton\n",
      "Processing weather for station Truckee / Polaris\n",
      "Processing weather for station Weaverville\n",
      "Processing weather for station Susanville / Johnstonville\n",
      "Processing weather for station Red Bluff Municipal Airport\n",
      "Processing weather for station Riverside / Arlanza\n",
      "Processing weather for station Grass Valley / Forest Knolls\n",
      "Processing weather for station Murrieta/Temecula / Murrieta Hot Springs (Historical)\n",
      "Processing weather for station Imperial\n",
      "Processing weather for station Byron\n",
      "Processing weather for station Lemoore Naval Air Station\n",
      "Processing weather for station Santa Ynez\n",
      "Processing weather for station Beale Afb / Oroville Junction\n",
      "Processing weather for station Hemet / Egan\n",
      "Processing weather for station Madera / Notarb\n",
      "Processing weather for station Santa Rosa / Shiloh\n",
      "Processing weather for station San Luis Obispo / Steele (Historical)\n",
      "Processing weather for station Riverside / March Air Force Base\n",
      "Processing weather for station Lemoore / Marnett\n",
      "Processing weather for station Santa Cruz / Isla Vista\n",
      "skipping Santa Cruz / Isla Vista\n",
      "Processing weather for station Lincoln / Ewing\n",
      "Processing weather for station Ukiah / Asylum\n",
      "Processing weather for station Palm Springs\n",
      "Processing weather for station Fairfield / Travis Air Force Base\n",
      "Processing weather for station San Jose / Alum Rock\n",
      "Processing weather for station Redding Municipal Airport\n",
      "Processing weather for station Sheridan, Ca\n",
      "Processing weather for station Petaluma / East Petaluma\n",
      "Processing weather for station Napa / Middleton\n",
      "Processing weather for station Leisure Town\n",
      "Processing weather for station Concord Buchanan Field\n",
      "Processing weather for station Hunter Ligget / Hunter-Liggett\n",
      "skipping Hunter Ligget / Hunter-Liggett\n",
      "Processing weather for station Merced / Castle Air Force Base\n",
      "Processing weather for station Crows Landing / Jet\n",
      "Processing weather for station Paso Robles / Estrella\n",
      "Processing weather for station Auburn Municipal Airport\n",
      "Processing weather for station Oceanside / Las Flores\n",
      "Processing weather for station Oxnard\n",
      "Processing weather for station Stevenson Ranch\n",
      "Processing weather for station San Diego / Town And Country Mobile Home Park\n",
      "Processing weather for station Campo\n",
      "Processing weather for station Sacramento / McClellan Park\n",
      "Processing weather for station Sacramento / Mather Field\n",
      "Processing weather for station Fresno Air Terminal\n",
      "Processing weather for station Merced\n",
      "Processing weather for station Corona\n",
      "Processing weather for station Lompoc Airport\n",
      "Processing weather for station San Andreas / Fourth Crossing\n",
      "Processing weather for station Tehachapi Municipal Airport\n",
      "Processing weather for station Porterville / Lois\n",
      "Processing weather for station Alturas / Juniper\n",
      "Processing weather for station Columbia / Springfield\n",
      "Processing weather for station Salinas / Spreckels Junction\n",
      "Processing weather for station Visalia / Midvalley\n",
      "Processing weather for station Borrego Springs\n",
      "skipping Borrego Springs\n",
      "Processing weather for station Bridgeport / Sonora Junction\n",
      "Processing weather for station Hollister / Cottage Corners\n",
      "Processing weather for station Point Piedras Blanca\n",
      "skipping Point Piedras Blanca\n",
      "Processing weather for station Lancaster / Antelope Acres\n",
      "Processing weather for station San Bernardino / North Norton\n",
      "Processing weather for station Livermore / East Pleasanton\n",
      "Processing weather for station San Martin\n",
      "Processing weather for station Los Angeles / Pacoima\n",
      "Processing weather for station Tracy Municipal Airport\n",
      "Processing weather for station Placerville / Smithflat\n",
      "Processing weather for station Big Bear City\n",
      "Processing weather for station Montague / Horizon Hills Mobile Home Park\n",
      "Processing weather for station Arcata / Clam Beach\n",
      "Processing weather for station Mammoth / Whitmore Hot Springs\n",
      "Processing weather for station Davis / Plainfield\n",
      "Processing weather for station Jackson / Sutter Hill\n",
      "Processing weather for station Sandberg\n",
      "Processing weather for station Eureka\n",
      "Processing weather for station San Diego / Bandini\n",
      "Processing weather for station Ontario International Airport\n",
      "Processing weather for station La Verne\n",
      "Processing weather for station Chester\n",
      "Processing weather for station Los Angeles / Jefferson\n",
      "Processing weather for station Bakersfield Meadows Field\n",
      "Processing weather for station Blue Canyon\n",
      "Processing weather for station Chico\n",
      "Processing weather for station Moffett Field\n",
      "Processing weather for station Monterey Regional Airport\n",
      "Processing weather for station Fallbrook / Deluz\n",
      "Processing weather for station Novato / Burdell\n",
      "Processing weather for station South Lake Tahoe / Tahoe Valley\n",
      "Processing weather for station Trinity Center\n",
      "Processing weather for station Lompoc, Vandenberg Air Force Base\n",
      "Processing weather for station Marysville / Alicia\n",
      "Processing weather for station Metro Oakland International  Airport\n",
      "Processing weather for station Irvine\n",
      "Processing weather for station Camarillo / Springville\n",
      "Processing weather for station Victorville Airport\n",
      "Processing weather for station Watsonville / Monterey Vista Mobile Home Park\n",
      "Processing weather for station Palo Alto / Runnymeade (Historical)\n",
      "Processing weather for station San Jose / Santa Clara Trailer Village\n",
      "Processing weather for station Thermal\n",
      "Processing weather for station Naws China Lake\n",
      "Processing weather for station Montague / Snowden\n",
      "Processing weather for station Julian CDF\n",
      "Processing weather for station Sacramento Executive Airport\n",
      "Processing weather for station Palmdale / El Mirage\n",
      "Processing weather for station Santa Monica Municipal Airport\n",
      "Processing weather for station Modesto City / Riverside\n",
      "Processing weather for station Oceanside / Chappo\n",
      "Processing weather for station Bishop Airport\n",
      "Processing weather for station Ramona / Rosemont\n",
      "Processing weather for station Mount Shasta\n",
      "Processing weather for station Cable Arpt / College Heights\n",
      "Processing weather for station Crescent City / Crescent City North\n",
      "Processing weather for station Monterey / Del Monte\n",
      "Processing weather for station Santa Ana / Paularino\n",
      "Processing weather for station Santa Maria Public Airport\n",
      "Processing weather for station Blythe / Mesa Verde\n",
      "Processing weather for station San Carlos / Silver Penny Mobile Home Park\n",
      "Processing weather for station Oceano / Oceano Beach\n",
      "Processing weather for station El Centro, Naval Air Facility\n",
      "Processing weather for station Hayward / Russell City\n",
      "Processing weather for station Palmdale Prod Flight Plant\n",
      "Processing weather for station Apple Valley / Bell Mountain\n",
      "Processing weather for station Inyokern\n",
      "Processing weather for station Needles / Parker Junction\n",
      "Processing weather for station Fresno / West Park\n",
      "Processing weather for station Delano / Delano Mobile Home Park\n",
      "Processing weather for station Mojave / Chaffee\n",
      "Processing weather for station Cuddleback Gunnery Range\n",
      "skipping Cuddleback Gunnery Range\n",
      "Processing weather for station Carlsbad / Rancho Carlsbad Trailer Park\n",
      "Processing weather for station Stockton Metropolitan Airport\n",
      "Processing weather for station Daggett / Minneola\n",
      "Processing weather for station MCAS Miramar\n",
      "Processing weather for station Burbank-Glendale-Pasadena\n",
      "Processing weather for station Van Nuys / Raymer\n",
      "Processing weather for station Mount Wilson\n",
      "Processing weather for station El Monte / Hayes\n",
      "Processing weather for station San Diego International Airport\n"
     ]
    }
   ],
   "source": [
    "from meteostat import Point, Daily\n",
    "from datetime import datetime\n",
    "\n",
    "for station_id, daily_status in station_daily_status.items():\n",
    "    print(f\"Processing weather for station {station_id}\")\n",
    "    \n",
    "    # Get station info\n",
    "    station_row = cali_stations[cali_stations['name'] == station_id].iloc[0]\n",
    "    lat = station_row['latitude']\n",
    "    lon = station_row['longitude']\n",
    "    \n",
    "    # Fetch weather data\n",
    "    point = Point(lat, lon)\n",
    "    weather = Daily(point, datetime(2020, 1, 1), datetime.today()).fetch()\n",
    "    if weather.empty:\n",
    "        print(f\"skipping {station_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert index to string dates\n",
    "    weather.index = weather.index.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    for date_str in daily_status:\n",
    "    # Always unwrap fire flag safely\n",
    "        fire_flag = daily_status[date_str]\n",
    "        if isinstance(fire_flag, dict):\n",
    "            while isinstance(fire_flag, dict):\n",
    "                fire_flag = fire_flag.get('fire_recent')\n",
    "        else:\n",
    "            fire_flag = bool(fire_flag)  # ensure it's boolean\n",
    "\n",
    "        if date_str in weather.index:\n",
    "            row = weather.loc[date_str]\n",
    "            daily_status[date_str] = {\n",
    "                'fire_recent': fire_flag,\n",
    "                'tavg': row['tavg'],\n",
    "                'tmin': row['tmin'],\n",
    "                'tmax': row['tmax'],\n",
    "                'prcp': row['prcp'],\n",
    "                'snow': row['snow'],\n",
    "                'wdir': row['wdir'],\n",
    "                'wspd': row['wspd'],\n",
    "                'wpgt': row['wpgt'],\n",
    "                'pres': row['pres'],\n",
    "                'tsun': row['tsun']\n",
    "            }\n",
    "        else:\n",
    "            daily_status[date_str] = {\n",
    "                'fire_recent': fire_flag,\n",
    "                'tavg': None,\n",
    "                'tmin': None,\n",
    "                'tmax': None,\n",
    "                'prcp': None,\n",
    "                'snow': None,\n",
    "                'wdir': None,\n",
    "                'wspd': None,\n",
    "                'wpgt': None,\n",
    "                'pres': None,\n",
    "                'tsun': None\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f76a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 bad entries from station Fortuna / Alton\n",
      "Removed 0 bad entries from station Truckee / Polaris\n",
      "Removed 0 bad entries from station Weaverville\n",
      "Removed 0 bad entries from station Susanville / Johnstonville\n",
      "Removed 0 bad entries from station Red Bluff Municipal Airport\n",
      "Removed 0 bad entries from station Riverside / Arlanza\n",
      "Removed 0 bad entries from station Grass Valley / Forest Knolls\n",
      "Removed 0 bad entries from station Murrieta/Temecula / Murrieta Hot Springs (Historical)\n",
      "Removed 0 bad entries from station Imperial\n",
      "Removed 0 bad entries from station Byron\n",
      "Removed 0 bad entries from station Lemoore Naval Air Station\n",
      "Removed 0 bad entries from station Santa Ynez\n",
      "Removed 0 bad entries from station Beale Afb / Oroville Junction\n",
      "Removed 0 bad entries from station Hemet / Egan\n",
      "Removed 0 bad entries from station Madera / Notarb\n",
      "Removed 0 bad entries from station Santa Rosa / Shiloh\n",
      "Removed 0 bad entries from station San Luis Obispo / Steele (Historical)\n",
      "Removed 0 bad entries from station Riverside / March Air Force Base\n",
      "Removed 0 bad entries from station Lemoore / Marnett\n",
      "Removed 1953 bad entries from station Santa Cruz / Isla Vista\n",
      "Removed 0 bad entries from station Lincoln / Ewing\n",
      "Removed 0 bad entries from station Ukiah / Asylum\n",
      "Removed 0 bad entries from station Palm Springs\n",
      "Removed 0 bad entries from station Fairfield / Travis Air Force Base\n",
      "Removed 0 bad entries from station San Jose / Alum Rock\n",
      "Removed 0 bad entries from station Redding Municipal Airport\n",
      "Removed 0 bad entries from station Sheridan, Ca\n",
      "Removed 0 bad entries from station Petaluma / East Petaluma\n",
      "Removed 0 bad entries from station Napa / Middleton\n",
      "Removed 0 bad entries from station Leisure Town\n",
      "Removed 0 bad entries from station Concord Buchanan Field\n",
      "Removed 1953 bad entries from station Hunter Ligget / Hunter-Liggett\n",
      "Removed 0 bad entries from station Merced / Castle Air Force Base\n",
      "Removed 0 bad entries from station Crows Landing / Jet\n",
      "Removed 0 bad entries from station Paso Robles / Estrella\n",
      "Removed 0 bad entries from station Auburn Municipal Airport\n",
      "Removed 0 bad entries from station Oceanside / Las Flores\n",
      "Removed 0 bad entries from station Oxnard\n",
      "Removed 0 bad entries from station Stevenson Ranch\n",
      "Removed 0 bad entries from station San Diego / Town And Country Mobile Home Park\n",
      "Removed 0 bad entries from station Campo\n",
      "Removed 0 bad entries from station Sacramento / McClellan Park\n",
      "Removed 0 bad entries from station Sacramento / Mather Field\n",
      "Removed 0 bad entries from station Fresno Air Terminal\n",
      "Removed 0 bad entries from station Merced\n",
      "Removed 0 bad entries from station Corona\n",
      "Removed 0 bad entries from station Lompoc Airport\n",
      "Removed 0 bad entries from station San Andreas / Fourth Crossing\n",
      "Removed 0 bad entries from station Tehachapi Municipal Airport\n",
      "Removed 0 bad entries from station Porterville / Lois\n",
      "Removed 0 bad entries from station Alturas / Juniper\n",
      "Removed 0 bad entries from station Columbia / Springfield\n",
      "Removed 0 bad entries from station Salinas / Spreckels Junction\n",
      "Removed 0 bad entries from station Visalia / Midvalley\n",
      "Removed 1953 bad entries from station Borrego Springs\n",
      "Removed 0 bad entries from station Bridgeport / Sonora Junction\n",
      "Removed 0 bad entries from station Hollister / Cottage Corners\n",
      "Removed 1953 bad entries from station Point Piedras Blanca\n",
      "Removed 0 bad entries from station Lancaster / Antelope Acres\n",
      "Removed 0 bad entries from station San Bernardino / North Norton\n",
      "Removed 0 bad entries from station Livermore / East Pleasanton\n",
      "Removed 0 bad entries from station San Martin\n",
      "Removed 0 bad entries from station Los Angeles / Pacoima\n",
      "Removed 0 bad entries from station Tracy Municipal Airport\n",
      "Removed 0 bad entries from station Placerville / Smithflat\n",
      "Removed 0 bad entries from station Big Bear City\n",
      "Removed 0 bad entries from station Montague / Horizon Hills Mobile Home Park\n",
      "Removed 0 bad entries from station Arcata / Clam Beach\n",
      "Removed 0 bad entries from station Mammoth / Whitmore Hot Springs\n",
      "Removed 0 bad entries from station Davis / Plainfield\n",
      "Removed 0 bad entries from station Jackson / Sutter Hill\n",
      "Removed 0 bad entries from station Sandberg\n",
      "Removed 0 bad entries from station Eureka\n",
      "Removed 0 bad entries from station San Diego / Bandini\n",
      "Removed 0 bad entries from station Ontario International Airport\n",
      "Removed 0 bad entries from station La Verne\n",
      "Removed 0 bad entries from station Chester\n",
      "Removed 0 bad entries from station Los Angeles / Jefferson\n",
      "Removed 0 bad entries from station Bakersfield Meadows Field\n",
      "Removed 0 bad entries from station Blue Canyon\n",
      "Removed 0 bad entries from station Chico\n",
      "Removed 0 bad entries from station Moffett Field\n",
      "Removed 0 bad entries from station Monterey Regional Airport\n",
      "Removed 0 bad entries from station Fallbrook / Deluz\n",
      "Removed 0 bad entries from station Novato / Burdell\n",
      "Removed 0 bad entries from station South Lake Tahoe / Tahoe Valley\n",
      "Removed 0 bad entries from station Trinity Center\n",
      "Removed 0 bad entries from station Lompoc, Vandenberg Air Force Base\n",
      "Removed 0 bad entries from station Marysville / Alicia\n",
      "Removed 0 bad entries from station Metro Oakland International  Airport\n",
      "Removed 0 bad entries from station Irvine\n",
      "Removed 0 bad entries from station Camarillo / Springville\n",
      "Removed 0 bad entries from station Victorville Airport\n",
      "Removed 0 bad entries from station Watsonville / Monterey Vista Mobile Home Park\n",
      "Removed 0 bad entries from station Palo Alto / Runnymeade (Historical)\n",
      "Removed 0 bad entries from station San Jose / Santa Clara Trailer Village\n",
      "Removed 0 bad entries from station Thermal\n",
      "Removed 0 bad entries from station Naws China Lake\n",
      "Removed 0 bad entries from station Montague / Snowden\n",
      "Removed 0 bad entries from station Julian CDF\n",
      "Removed 0 bad entries from station Sacramento Executive Airport\n",
      "Removed 0 bad entries from station Palmdale / El Mirage\n",
      "Removed 0 bad entries from station Santa Monica Municipal Airport\n",
      "Removed 0 bad entries from station Modesto City / Riverside\n",
      "Removed 0 bad entries from station Oceanside / Chappo\n",
      "Removed 0 bad entries from station Bishop Airport\n",
      "Removed 0 bad entries from station Ramona / Rosemont\n",
      "Removed 0 bad entries from station Mount Shasta\n",
      "Removed 0 bad entries from station Cable Arpt / College Heights\n",
      "Removed 0 bad entries from station Crescent City / Crescent City North\n",
      "Removed 0 bad entries from station Monterey / Del Monte\n",
      "Removed 0 bad entries from station Santa Ana / Paularino\n",
      "Removed 0 bad entries from station Santa Maria Public Airport\n",
      "Removed 0 bad entries from station Blythe / Mesa Verde\n",
      "Removed 0 bad entries from station San Carlos / Silver Penny Mobile Home Park\n",
      "Removed 0 bad entries from station Oceano / Oceano Beach\n",
      "Removed 0 bad entries from station El Centro, Naval Air Facility\n",
      "Removed 0 bad entries from station Hayward / Russell City\n",
      "Removed 0 bad entries from station Palmdale Prod Flight Plant\n",
      "Removed 0 bad entries from station Apple Valley / Bell Mountain\n",
      "Removed 0 bad entries from station Inyokern\n",
      "Removed 0 bad entries from station Needles / Parker Junction\n",
      "Removed 0 bad entries from station Fresno / West Park\n",
      "Removed 0 bad entries from station Delano / Delano Mobile Home Park\n",
      "Removed 0 bad entries from station Mojave / Chaffee\n",
      "Removed 1953 bad entries from station Cuddleback Gunnery Range\n",
      "Removed 0 bad entries from station Carlsbad / Rancho Carlsbad Trailer Park\n",
      "Removed 0 bad entries from station Stockton Metropolitan Airport\n",
      "Removed 0 bad entries from station Daggett / Minneola\n",
      "Removed 0 bad entries from station MCAS Miramar\n",
      "Removed 0 bad entries from station Burbank-Glendale-Pasadena\n",
      "Removed 0 bad entries from station Van Nuys / Raymer\n",
      "Removed 0 bad entries from station Mount Wilson\n",
      "Removed 0 bad entries from station El Monte / Hayes\n",
      "Removed 0 bad entries from station San Diego International Airport\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_stations = list(station_daily_status.keys())\n",
    "\n",
    "for sample_station in sample_stations:\n",
    "    # Collect dates to remove\n",
    "    dates_to_remove = []\n",
    "    \n",
    "    for date, data in station_daily_status[sample_station].items():\n",
    "        if isinstance(data, bool):\n",
    "            dates_to_remove.append(date)\n",
    "    \n",
    "    # Remove them after looping (avoid modifying dict during iteration)\n",
    "    for date in dates_to_remove:\n",
    "        del station_daily_status[sample_station][date]\n",
    "    \n",
    "    print(f\"Removed {len(dates_to_remove)} bad entries from station {sample_station}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfc0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253890 entries, 0 to 253889\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   station_id   253890 non-null  object \n",
      " 1   date         253890 non-null  object \n",
      " 2   fire_recent  253890 non-null  int64  \n",
      " 3   tavg         247461 non-null  float64\n",
      " 4   tmin         248772 non-null  float64\n",
      " 5   tmax         248773 non-null  float64\n",
      " 6   prcp         239936 non-null  float64\n",
      " 7   snow         26332 non-null   float64\n",
      " 8   wdir         242918 non-null  float64\n",
      " 9   wspd         246385 non-null  float64\n",
      " 10  wpgt         0 non-null       float64\n",
      " 11  pres         240616 non-null  float64\n",
      " 12  tsun         0 non-null       float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Flatten to rows\n",
    "\n",
    "def unwrap_fire_recent(value):\n",
    "    # Unwrap repeatedly if it's still a dict\n",
    "    while isinstance(value, dict):\n",
    "        value = value.get('fire_recent')\n",
    "    return int(bool(value))  # ensure we get 0 or 1\n",
    "\n",
    "rows = []\n",
    "\n",
    "missed_data_count = 0\n",
    "\n",
    "for station_id, daily_data in station_daily_status.items():\n",
    "    for date, data in daily_data.items():\n",
    "        row = {\n",
    "            'station_id': station_id,\n",
    "            'date': date,\n",
    "            'fire_recent': int(data['fire_recent']),  # convert to 0/1\n",
    "            'tavg': data['tavg'],\n",
    "            'tmin': data['tmin'],\n",
    "            'tmax': data['tmax'],\n",
    "            'prcp': data['prcp'],\n",
    "            'snow': data['snow'],\n",
    "            'wdir': data['wdir'],\n",
    "            'wspd': data['wspd'],\n",
    "            'wpgt': data['wpgt'],\n",
    "            'pres': data['pres'],\n",
    "            'tsun': data['tsun']\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.info()\n",
    "df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d209238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire days: 5798, Non-fire days: 248092\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have df built\n",
    "fire_df = df[df['fire_recent'] == 1]\n",
    "nonfire_df = df[df['fire_recent'] == 0]\n",
    "print(f\"Fire days: {len(fire_df)}, Non-fire days: {len(nonfire_df)}\")\n",
    "\n",
    "nonfire_sampled = nonfire_df.sample(n=len(fire_df), random_state=42)\n",
    "balanced_df = pd.concat([fire_df, nonfire_sampled]).sample(frac=1, random_state=42)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c68c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_cols = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun']\n",
    "X = balanced_df[feature_cols].values\n",
    "\n",
    "\n",
    "y = balanced_df['fire_recent'].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85df58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_cols = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun']\n",
    "X = balanced_df[feature_cols].values\n",
    "y = balanced_df['fire_recent'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb187d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      1160\n",
      "           1       0.70      0.78      0.74      1160\n",
      "\n",
      "    accuracy                           0.72      2320\n",
      "   macro avg       0.73      0.72      0.72      2320\n",
      "weighted avg       0.73      0.72      0.72      2320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3968a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fire       0.75      0.67      0.71      1160\n",
      "        Fire       0.70      0.78      0.74      1160\n",
      "\n",
      "    accuracy                           0.72      2320\n",
      "   macro avg       0.73      0.72      0.72      2320\n",
      "weighted avg       0.73      0.72      0.72      2320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['No Fire', 'Fire']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f9a84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8a62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5213 - loss: 6.3312 - val_accuracy: 0.6405 - val_loss: 0.6593\n",
      "Epoch 2/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5367 - loss: 1.9145 - val_accuracy: 0.5112 - val_loss: 2.0006\n",
      "Epoch 3/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5693 - loss: 1.3530 - val_accuracy: 0.5095 - val_loss: 1.5651\n",
      "Epoch 4/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5630 - loss: 1.4054 - val_accuracy: 0.5134 - val_loss: 2.0481\n",
      "Epoch 5/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5587 - loss: 1.3751 - val_accuracy: 0.6388 - val_loss: 1.0170\n",
      "Epoch 6/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5764 - loss: 1.3159 - val_accuracy: 0.5629 - val_loss: 1.7232\n",
      "Epoch 7/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5947 - loss: 1.6897 - val_accuracy: 0.4940 - val_loss: 3.7120\n",
      "Epoch 8/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5833 - loss: 1.4901 - val_accuracy: 0.6698 - val_loss: 0.9404\n",
      "Epoch 9/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6009 - loss: 1.2511 - val_accuracy: 0.5655 - val_loss: 1.6137\n",
      "Epoch 10/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5951 - loss: 1.8990 - val_accuracy: 0.6284 - val_loss: 1.5003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3958a2650>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-m1)",
   "language": "python",
   "name": "tf-m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
